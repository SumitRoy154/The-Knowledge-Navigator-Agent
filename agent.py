import logging
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain.tools import StructuredTool
from pydantic import BaseModel, Field

# Local imports
from config import GEMINI_API_KEY
from tools.course_finder import search_online_courses
from tools.roadmap_generator import generate_learning_roadmap

# Configure basic logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- System Prompt Definition ---
SYSTEM_PROMPT = """
You are a friendly, formal, and resourceful Academic Advisor named the Knowledge Navigator.
Your tone is helpful, encouraging, and highly data-driven.
Your primary goal is to act as a comprehensive guide for users looking to learn a new topic.

**Agent Workflow:**
1.  When a user expresses a desire to learn about a broad topic (e.g., "I want to learn AI"), you MUST first use the `generate_learning_roadmap` tool to create a structured learning plan.
2.  After generating the roadmap, you MUST then immediately use the `search_online_courses` tool to find relevant beginner courses for that same topic.
3.  Finally, you must synthesize the information from both tools into a single, comprehensive response.

**Response Structure:**
- Start with a friendly introduction.
- Present the detailed, multi-phase learning roadmap generated by the tool.
- Present the course recommendations found by the search tool in a clear, structured format (like a table).
- Conclude with a helpful summary and next steps.

**Constraint Rules:**
- NEVER invent or hallucinate course data. Only use the exact data returned by the `search_online_courses` tool.
- If the search tool returns no results, you must still present the learning roadmap and then clearly state that you could not find any specific courses.
"""

# --- Pydantic Model for the Tool's Arguments ---
class CourseSearchArgs(BaseModel):
    topic: str = Field(description="The main subject or topic of the courses to search for.")
    max_price: float = Field(default=None, description="The maximum budget for the course in USD.")
    min_rating: float = Field(default=None, description="The minimum user rating for the course (e.g., 4.5).")

# --- Agent Class ---
class Agent:
    def __init__(self):
        # 1. Initialize the LLM
        # Configure the model with the API key and latest model name
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            google_api_key=GEMINI_API_KEY,
            temperature=0.7
        )

        # 2. Define the custom tools
        tools = [
            StructuredTool.from_function(
                func=generate_learning_roadmap,
                name="generate_learning_roadmap",
                description="Generates a structured, multi-phase learning roadmap for a given topic.",
            ),
            StructuredTool.from_function(
                func=search_online_courses,
                name="search_online_courses",
                description="Searches for online courses based on topic, budget, and rating preferences.",
                args_schema=CourseSearchArgs
            )
        ]

        # 3. Create the Agent Prompt Template
        prompt = ChatPromptTemplate.from_messages([
            ("system", SYSTEM_PROMPT),
            ("placeholder", "{chat_history}"),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}"),
        ])

        # 4. Create the Agent
        agent = create_tool_calling_agent(self.llm, tools, prompt)

        # 5. Create the Agent Executor
        self.executor = AgentExecutor(
            agent=agent, 
            tools=tools, 
            verbose=True, # Set to True to see agent's thought process
            handle_parsing_errors=True # Gracefully handle any LLM output errors
        )

    def format_response(self, response):
        """Format the agent's response to be clean and consistent."""
        # If the response is a list of courses, format it nicely
        if isinstance(response, list) and all(isinstance(item, dict) and 'course_name' in item for item in response):
            formatted = "\nHere are some recommended courses for you:\n"
            for i, course in enumerate(response, 1):
                formatted += f"\n{i}. {course['course_name']}"
                formatted += f"\n   Platform: {course['platform_name']}"
                formatted += f"\n   Price: {'Free' if course['price_usd'] == 0.0 else f'${course['price_usd']}'}"
                formatted += f"\n   Rating: {course['average_rating']}/5"
                formatted += f"\n   Duration: {course['duration_weeks']} weeks"
                formatted += f"\n   Link: {course['course_url']}\n"
            return formatted
            
        # For regular text responses, clean up formatting
        if isinstance(response, str):
            # Remove any color codes or special formatting
            import re
            response = re.sub(r'\x1b\[([0-9A-Za-z;?]?[0-9]*)*[m|K]?', '', response)
            
            # Clean up the response
            lines = [line.strip() for line in response.split('\n') if line.strip()]
            return '\n'.join(lines)
            
        return str(response)

    def invoke(self, user_input: str, chat_history: list):
        """Invokes the agent with user input and chat history, returning the response."""
        logging.info(f"Invoking agent with input: '{user_input}' and history: {len(chat_history)} messages")
        try:
            # Process the input
            response = self.executor.invoke({
                "input": user_input,
                "chat_history": [msg for msg in chat_history if not isinstance(msg, dict)]
            })
            
            full_response = response['output']
            formatted_response = self.format_response(full_response)
            
            # Store the response in the chat history
            chat_history.append({
                'user_input': user_input,
                'response': formatted_response
            })
                
            logging.info("Agent response formatted")
            return formatted_response
            
        except Exception as e:
            error_msg = f"I'm sorry, but I encountered an error: {str(e)}"
            logging.error(f"Error in agent invocation: {error_msg}")
            return error_msg
